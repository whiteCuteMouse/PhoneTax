import streamlit as st
import pandas as pd
import re
import altair as alt

from konlpy.tag import Okt
from collections import Counter
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import pickle
#pd.set_option('display.max_columns', None) #df ì¶œë ¥ ì‹œ ëª¨ë“  ì—´ ì¶œë ¥
#pd.set_option('display.max_rows', None) #df ì¶œë ¥ ì‹œ ëª¨ë“  í–‰ ì¶œë ¥
#pd.reset_option("display") display option ì´ˆê¸°í™”
#%%
#í˜ì´ì§€ì— ê´€í•œ ì •ë³´
try:
   st.set_page_config(
      page_title="í¬ë„·íƒìŠ¤ íŒ€ ì±—ë´‡ ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™”: ëŒ€ì‹œ ë³´ë“œ",
      page_icon="ğŸ“Š",
      layout="wide",#centeredê°€ ê¸°ë³¸ê°’. ê³ ì • ë„ˆë¹„ ì•ˆì— elementë“¤ì„ ì œí•œ. wideëŠ” í™”ë©´ ì „ì²´ë¥¼ ì‚¬ìš©í•¨.
      initial_sidebar_state="expanded")
except:
   pass
PRIMARY_COLOR = "#872434"
#html <p>ì— ê¸€ì”¨ ì“°ê¸°
def p_write(txt, font_size = 10, font_weight = "normal", text_align = "center", font_style = "normal", color = "black", writeHTML=True):
    r = f'<p style="font-family:Malgun Gothic; text-align:{text_align}; font-size: {font_size}px; font-weight: {font_weight}; font-style: {font_style}; color: {color}">{txt}</p>'
    if writeHTML:
        st.markdown(r, unsafe_allow_html=True)
    return r
#html <span>ì— ê¸€ì”¨ ì“°ê¸°
#spanì—ëŠ” text-align ì†ì„±ì´ ì—†ìŒ
def span_write(txt, font_size = 10, font_weight = "normal", font_style = "normal", color = "black", writeHTML = True):
    r = f'<span style="font-family:Malgun Gothic; font-size: {font_size}px; font-weight: {font_weight}; font-style: {font_style}; color: {color}">{txt}</span>'
    if writeHTML:
        st.markdown(r, unsafe_allow_html=True)
    return r

#st.title("*í¬ë„·íƒìŠ¤* ëŒ€ì‹œ ë³´ë“œ")
title1 = span_write("PhoneTax", 40, "bold", "italic", PRIMARY_COLOR, writeHTML=False)
title2 = span_write(" Dashboard", 40, "bold", "normal", writeHTML=False)
st.markdown(f'{title1}{title2}', unsafe_allow_html=True)
#st.markdown('<span style="font-family:Malgun Gothic; font-size: 44px; font-weight: bold; font-style: italic; color: #872434">í¬ë„·íƒìŠ¤</span><span style="font-family:Malgun Gothic; font-size: 44px; font-weight: bold"> ëŒ€ì‹œë³´ë“œ</span>', unsafe_allow_html=True)
#%%
#ë°ì´í„° ë¡œë”© ë° ì´ˆê¸°í™”

def str_to_timedelta(str_t):
    if type(str_t) == str:
        s = re.search(r"(\d+)[h]\s*(\d+)[m]\s*(\d+)[s]", str_t)
        
        return pd.Timedelta(hours=int(s.group(1)), minutes=int(s.group(2)), seconds=int(s.group(3)))
    else:#ê²°ì¸¡ì¹˜ì¸ ê²½ìš° ë„˜ì–´ê°€ê¸°
        return #pd.Timedelta(hours=int(s.group(0)), minutes=int(s.group(0)), seconds=int(s.group(0)))

# ì„¸ íŒŒì¼ì˜ sheetë“¤ì„ ê°ê° í•©ì¹˜ê¸°
@st.cache_data
def load_data():
    fnames = ["2022.01.01~2022.06.30ì±—ë´‡ë°ì´í„°.xlsx", "2022.07.01~2022.12.31.xlsx", "2023.01.01~2023.06.30.xlsx"]


    df_UserChat = pd.DataFrame([])
    df_User = pd.DataFrame([])
    df_Message = pd.DataFrame([])
    df_UserChatTag = pd.DataFrame([])
    
    for fname in fnames:
        sheet_UserChat = pd.read_excel(fname, engine = 'openpyxl', sheet_name = 'UserChat data')
        sheet_User = pd.read_excel(fname, engine = 'openpyxl', sheet_name = 'User data')
        sheet_Message = pd.read_excel(fname, engine = 'openpyxl', sheet_name = 'Message data')
        sheet_UserChatTag = pd.read_excel(fname, engine = 'openpyxl', sheet_name = 'UserChatTag data')
        
        df_UserChat = pd.concat([df_UserChat, sheet_UserChat], axis=0, ignore_index=True) #axis=0ë¡œ í–‰ ë°©í–¥(ì„¸ë¡œ) ê²°í•©
        df_User = pd.concat([df_User, sheet_User], axis=0, ignore_index=True)
        df_Message = pd.concat([df_Message, sheet_Message], axis=0, ignore_index=True)
        df_UserChatTag = pd.concat([df_UserChatTag, sheet_UserChatTag], axis=0, ignore_index=True)
    
    #ë‚ ì§œ ë°ì´í„° í˜•ì‹ ë³€í™˜(ëŒ€ì†Œ ë¹„êµ ë“±ì„ ìœ„í•´)
    #df_Userì™€ ë‚˜ë¨¸ì§€ì˜ ë‚ ì§œ í˜•ì‹ì´ ë‹¤ë¦„!
    df_User['lastSeenAt'] = pd.to_datetime(df_User['lastSeenAt'], format='mixed', infer_datetime_format=True)#infer_datetime_format=TrueëŠ” pandasê°€ ìë™ìœ¼ë¡œ í˜•ì‹ ì¶”ë¡ 
    df_User['updatedAt'] = pd.to_datetime(df_User['updatedAt'], format='mixed', infer_datetime_format=True)
    df_User['createdAt'] = pd.to_datetime(df_User['createdAt'], format='mixed', infer_datetime_format=True)
    df_User['web.lastSeenAt'] = pd.to_datetime(df_User['web.lastSeenAt'], format='mixed', infer_datetime_format=True)
    
    
    df_Message['createdAt'] = pd.to_datetime(df_Message['createdAt'], format='mixed', infer_datetime_format=True)
    df_UserChatTag['UserChatTag data'] = pd.to_datetime(df_UserChatTag['createdAt'], format='mixed', infer_datetime_format=True)
    
    df_UserChat['firstOpenedAt'] = pd.to_datetime(df_UserChat['firstOpenedAt'], format='mixed', infer_datetime_format=True)
    df_UserChat['openedAt'] = pd.to_datetime(df_UserChat['openedAt'], format='mixed', infer_datetime_format=True)
    df_UserChat['firstRepliedAtAfterOpen'] = pd.to_datetime(df_UserChat['firstRepliedAtAfterOpen'], format='mixed', infer_datetime_format=True)
    df_UserChat['createdAt'] = pd.to_datetime(df_UserChat['createdAt'], format='mixed', infer_datetime_format=True)
    df_UserChat['closedAt'] = pd.to_datetime(df_UserChat['closedAt'], format='mixed', infer_datetime_format=True)
    
    #UserChat ì‹œíŠ¸ì˜ waitingTime ë“±ë“±ì„ timedelta í˜•ì‹ìœ¼ë¡œ ë°”ê¾¸ê¸°
    df_UserChat['waitingTime'] = df_UserChat['waitingTime'].apply(str_to_timedelta)
    df_UserChat['avgReplyTime'] = df_UserChat['avgReplyTime'].apply(str_to_timedelta)
    df_UserChat['totalReplyTime'] = df_UserChat['totalReplyTime'].apply(str_to_timedelta)
    df_UserChat['resolutionTime'] = df_UserChat['resolutionTime'].apply(str_to_timedelta)
    df_UserChat['operationWaitingTime'] = df_UserChat['operationWaitingTime'].apply(str_to_timedelta)
    df_UserChat['operationAvgReplyTime'] = df_UserChat['operationAvgReplyTime'].apply(str_to_timedelta)
    df_UserChat['operationTotalReplyTime'] = df_UserChat['operationTotalReplyTime'].apply(str_to_timedelta)
    
    r = dict()
    r['UserChat'] = df_UserChat
    r['User'] = df_User
    r['Message'] = df_Message
    r['UserChatTag'] = df_UserChatTag
    return r

#ë¡œë”©ì´ ëë‚¬ìœ¼ë©´ ë°ì´í„° ì „ì²˜ë¦¬
@st.cache_data
def data_init(dfs):
    # *************** df_User ì „ì²˜ë¦¬ ***************
    #print(df_User)
    # ì¤‘ë³µëœ User dataì˜ í–‰ ì—†ì• ê¸°(idë¥¼ ê¸°ì¤€ìœ¼ë¡œ)
    dfs['User'] = dfs['User'].drop_duplicates(subset='id')
    
    #í•™ì /ê³¼ì •/í•™ë…„ NaN ì²˜ë¦¬
    #ì •í™•íˆ ì„¸ê¸° ìœ„í•´ì„œ ê²°ì¸¡ì¹˜ nanì„ ì‹¤ì œ ê°’ìœ¼ë¡œ ì±„ì›Œì•¼ í•¨.
    NaN_cols = ['profile.user_role', 'profile.course_role', 'profile.education_level']
    for col in NaN_cols:
        dfs['User'][col].fillna('ë¯¸ì‹ë³„(ë¡œê·¸ì¸ ì•ˆ í•¨)', inplace=True)#inplace Trueë¡œ í•˜ë©´ ì›ë³¸ ë°ì´í„° ìˆ˜ì •
    
    # *************** df_UserChatTag ì „ì²˜ë¦¬ ***************
    # ì¤‘ë³µëœ UserChatTag dataì˜ í–‰ ì—†ì• ê¸°(idë¥¼ ê¸°ì¤€ìœ¼ë¡œ)
    dfs['UserChatTag'] = dfs['UserChatTag'].drop_duplicates(subset='id')
    
    
    # *************** df_Message ì „ì²˜ë¦¬ ***************
    #ë‚ ì§œë¥¼ ê¸°ì¤€ìœ¼ë¡œ df_Message ì •ë ¬
    dfs['Message'] = dfs['Message'].sort_values(by='createdAt')
    #print(len(set(dfs[2]['chatId']))) #4563
    
    #ë¨¼ì € personTypeì´ userì¸ í–‰ë§Œ ê±¸ëŸ¬ë‚´ê¸°
    dfs['Message'] = dfs['Message'][dfs['Message']['personType'] == 'user']
    #print(len(set(dfs[2]['chatId']))) #4547
    
    #ì‹¤ì œ userì¸ í–‰ë§Œ ê±¸ëŸ¬ë‚´ê¸°(Userì— ë“±ë¡ëœ idì™€ ë¹„êµ)
    #print(dfs[2][~dfs[2]['personId'].isin(set(dfs[1]['id']))])
    dfs['Message'] = dfs['Message'][dfs['Message']['personId'].isin(set(dfs['User']['id']))]
    #print(len(set(dfs[2]['chatId']))) #3917
    
    #df_UserChat ì „ì²˜ë¦¬ ì´í›„ df_Message í•œ ë²ˆ ë” ì „ì²˜ë¦¬ í•„ìš”(ì„œë¡œì˜ chatId(df_UserChatì€ id)ê°€ ì„œë¡œì—ê²Œ ìˆëŠ” ê²ƒë§Œ ë‚¨ê¹€)
    
    # *************** df_UserChat ì „ì²˜ë¦¬ ***************
    #operationReplyCountë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²°ì¸¡ì¹˜ ì œê±°
    #print("ì œê±° ì´ì „ ìˆ˜", len(set(dfs[0]['id'])))#4563ê°œ
    dfs['UserChat'] = dfs['UserChat'].dropna(subset=['operationReplyCount'])
    #print("ì œê±° ì´í›„ ìˆ˜", len(set(dfs[0]['id']))) #ì œê±° ì´í›„ 3342
    
    #ì‹¤ì œ ì±„íŒ… ë‚´ì—­ ë°ì´í„°(Message)ë‘ ë¹„êµí–ˆì„ ë• ë” ì¤„ì–´ë“¦ 
    #df_Messageì— chatIdì™€ ë™ì¼í•œ ê²ƒë§Œ ê±¸ëŸ¬ë‚´ê¸°
    dfs['UserChat'] = dfs['UserChat'][dfs['UserChat']['id'].isin(set(dfs['Message']['chatId']))]
    #print("Messageì˜ chatIdì™€ ê²¹ì¹˜ëŠ” ê²ƒë§Œ ê°œìˆ˜", len(set(dfs[0]['id'])))#3688
    
    #tagaì—´ì˜ ê²°ì¸¡ì¹˜ëŠ” 'íƒœê·¸ ì—†ìŒ'ìœ¼ë¡œ ì²˜ë¦¬
    dfs['UserChat']['tags'] = dfs['UserChat']['tags'].fillna('íƒœê·¸ ì—†ìŒ')
    
    # df_Message ì „ì²˜ë¦¬2
    dfs['Message'] = dfs['Message'][dfs['Message']['chatId'].isin(set(dfs['UserChat']['id']))]
    
    #print(filtered_df_Message)
    
    #personTypeì´ userì¸ ê²ƒë§Œ í¬í•¨í•œ Messageì— ìˆëŠ” chatId ê°œìˆ˜ë³´ë‹¤ UserChatì— ìˆëŠ” idê°€ ë§ìŒ.
    #ì¦‰, Messageì˜ chatId ìˆ˜ < UserChatì˜ id ìˆ˜
    #í™•ì¸ ê²°ê³¼ UserChatì—ëŠ” ìˆì§€ë§Œ Messageì—ëŠ” ì•„ì˜ˆ ì—†ëŠ” ê²½ìš°ë„ ìˆê³ , managerë¼ì„œ ë¹ ì§„ ê²½ìš°ë„ ìˆìŒ.
    #ë”°ë¼ì„œ ì‹¤ì œ userê°€ ëŒ€í™”í•œ ê²ƒìœ¼ë¡œ íŒë‹¨ë˜ëŠ” ê²ƒì„ ì„¸ë ¤ë©´ userë§Œ í¬í•¨í•œ Messageì— ìˆëŠ” chatIdë¥¼ ì„¸ì•¼ í•¨.
    
    #UserChatê³¼ Messageì˜ ìˆ˜ê°€ ê°™ì•„ì•¼ í•¨
    #ê°ê° 2889ê°œë¡œ ê°™ìŒ
    #print(len(set(dfs[0]['id'])), len(set(dfs[2]['chatId'])))
    
    return dfs

# Session Initialization
# ì„¸ì…˜ì€ ë°ì´í„°ë¥¼ ì „ì—­ ë³€ìˆ˜ì²˜ëŸ¼ ì €ì¥í•´ ë†“ëŠ” ê¸°ëŠ¥. í™”ë©´ ì¡°ì‘ì„ í•  ë•Œë§ˆë‹¤ íŒŒì´ì¬ ì½”ë“œë¥¼ ì²˜ìŒë¶€í„° ì‹¤í–‰í•˜ëŠ”ë°, ì„¸ì…˜ì— ë„£ì–´ë‘ë©´ ê°’ ì´ˆê¸°í™”ë¥¼ ê±´ë„ˆë›¸ ìˆ˜ ìˆìŒ.
# ì£¼ì˜: ìºì‹œë‘ì€ ë‹¤ë¥¸ ê°œë…!! ìºì‹œëŠ” ìì£¼ ì‚¬ìš©í•˜ëŠ” ê°’ì„ ë¡œë“œí•´ ë†“ëŠ” ê²ƒì¸ ë°˜ë©´(í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨í•´ë„ ë‚¨ì•„ ìˆìŒ), ì„¸ì…˜ì€ ê°’ì„ ì—°ì†ì„± ìˆê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡(ì˜ˆ: ë¡œê·¸ì¸ ìƒíƒœ ì €ì¥) í•˜ëŠ” ê²ƒì„.
# ìºì‹œëŠ” ë¡œì»¬ì— ì €ì¥, ì„¸ì…˜ì€ ì„œë²„ ë˜ëŠ” í´ë¼ì´ì–¸íŠ¸ì— ì €ì¥
if 'dfs' not in st.session_state:
    dfs = st.session_state['dfs'] = data_init(load_data())
else:
    dfs = st.session_state['dfs']
    
#ë°ì´í„° ë¡œë”© ë° ì´ˆê¸°í™” ë
#í™”ë©´ í‘œì‹œ
#sidebar
with st.sidebar:
    st.header("í‘œì‹œ ì„¤ì •")
    show_all = st.toggle('ìƒëµ ì—†ì´ ëª¨ë“  ì •ë³´ í‘œì‹œ')
    if show_all:
        st.write("í˜„ì¬ :red[***ìƒëµ ì—†ì´ ëª¨ë“  ì •ë³´ë¥¼ í‘œì‹œ***]í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
    else:
        st.write("í˜„ì¬ ì „ì²´ ëŒ€ë¹„ :red[***5% ë¯¸ë§Œì¸ ì •ë³´ë“¤ì„'ê¸°íƒ€'ë¡œ ì²˜ë¦¬***]í•˜ê³  ìˆìŠµë‹ˆë‹¤.")
    
    use_phnetax_theme = st.toggle('í¬ë„·íƒìŠ¤ í…Œë§ˆ ì‚¬ìš©', value=True)
            #ê°•ì‚¬, êµì› : íŒŒë€ìƒ‰ ê³„ì—´
            #ëŒ€í•™ì› : ë¶‰ì€ìƒ‰ ê°œì—´
            #í•™ë¶€ : ì´ˆë¡ìƒ‰ ê³„ì—´
            #ê¸°íƒ€ : íšŒìƒ‰ ê³„ì—´
    st.write("í¬ë„·íƒìŠ¤ í…Œë§ˆë¥¼ ì‚¬ìš©í•˜ë©´ :green[**í•™ë¶€ëŠ” ì´ˆë¡ìƒ‰ ê³„ì—´**], :red[**ëŒ€í•™ì›ì€ ë¶‰ì€ìƒ‰ ê³„ì—´**], :blue[**ê°•ì‚¬ ë° êµì›ì€ íŒŒë€ìƒ‰ ê³„ì—´**], :grey[**ë‚˜ë¨¸ì§€ëŠ” íšŒìƒ‰ ê³„ì—´**]ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.")
    
    st.header("í™”ë©´ ì—…ë°ì´íŠ¸ ì„¤ì •")
    if 'keyword_rating_update' in st.session_state:#ìƒëŒ€ ê±°ì— ë§ì¶”ê¸°
        keyword_rating_update = st.toggle('í‚¤ì›Œë“œ ìˆœìœ„ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸', value=st.session_state['keyword_rating_update'], key='keyword_rating_update_side')
    else:
        keyword_rating_update = st.toggle('í‚¤ì›Œë“œ ìˆœìœ„ ê·¸ë˜í”„ ì—…ë°ì´íŠ¸', value=True, key='keyword_rating_update_side')
    if 'word_cloud_update' in st.session_state:
        word_cloud_update = st.toggle('í‚¤ì›Œë“œ ì‹œê°í™” ì´ë¯¸ì§€ ì—…ë°ì´íŠ¸', value=st.session_state['word_cloud_update'], key='word_cloud_update_side')
    else:
        ord_cloud_update = st.toggle('í‚¤ì›Œë“œ ì‹œê°í™” ì´ë¯¸ì§€ ì—…ë°ì´íŠ¸', value=True, key='word_cloud_update_side')
        
    st.header("í¬ë„·íƒìŠ¤(PhoneTax) íŒ€ ì†Œê°œ")
    st.write("í¬ë„·íƒìŠ¤ëŠ” ìŒìš´ë¡ ì˜ 'Phonology', í†µì‚¬ë¡ ì˜ 'Syntax'ì˜ í•©ì„±ì–´ì…ë‹ˆë‹¤. ê°ê° ìŒìš´ë¡ ê³¼ í†µì‚¬ë¡ ì˜ ìì—°ì–´ì²˜ë¦¬ì— ê´€ì‹¬ì´ ìˆëŠ” ê³ ë ¤ëŒ€í•™êµ êµ­ì–´êµ­ë¬¸í•™ê³¼ ì„ì‚¬ ê³¼ì •ìƒ ì•ˆì˜ˆì§„, ì´ì˜ˆëŒì´ ì†Œì†ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    st.markdown("ì•ˆì˜ˆì§„ : ruizhen42@korea.ac.kr<br>ì´ì˜ˆëŒ : dpfka248@korea.ac.kr", unsafe_allow_html=True)
#%%
with st.container():#containerì€ í™”ë©´ìƒ ê°€ë¡œë¡œ ë‚˜ëˆ”
    # íŠ¹ì • ì—´ì˜ ëª¨ë“  Timestampë¥¼ normalizeí•˜ëŠ” í•¨ìˆ˜(normalizeëŠ” ì‹œ, ë¶„, ì´ˆ ì •ë³´ ì§€ì›€)
    def normalize_timestamp(timestamp):
         return timestamp.normalize()
     
    #ì‹œ, ë¶„, ì´ˆ ì •ë³´ê°€ ì§€ì›Œì§„ timestampë¥¼ ë¬¸ìì—´ë¡œ ë§Œë“¤ê¸°
    def convert_to_date_in_string(timestamp):
        return timestamp.strftime("%Yë…„ %mì›” %dì¼")
    
    @st.cache_data
    def init_slider_data():
        #ì±„íŒ…ì˜ ê°€ì¥ ì´ë¥¸ ë‚ ì§œì™€ ê°€ì¥ ëŠ¦ì€ ë‚ ì§œë¥¼ ì•Œì•„ë‚´ê¸°(UserChat ì´ìš©)
        #UserChatì˜ firstOpenedAtì´ Messageì˜ createdAtê³¼ ë™ì¼í•¨.
        earliest_timestamp = dfs['UserChat']['firstOpenedAt'].min()
        latest_timestamp = dfs['UserChat']['firstOpenedAt'].max()
    
        # timestampë¥¼ ê¹Šì€ ë³µì‚¬ í›„ normalizeí•´ì„œ ì‹œê°„, ë¶„, ì´ˆ ì •ë³´ëŠ” ì§€ìš°ê¸°
        opt = dfs['UserChat']['firstOpenedAt'].copy()
        opt = opt.apply(normalize_timestamp)
        
        #ì¤‘ë³µëœ ë‚ ì§œ ì œê±°
        opt = opt.drop_duplicates()
        #timestampë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        opt = opt.apply(convert_to_date_in_string)
        
        return earliest_timestamp, latest_timestamp, opt
    st.session_state['slider'] = init_slider_data()#ìŠ¬ë¼ì´ë” ê´€ë ¨ ê°’ì€ ì„¸ì…˜ì—. ì´ê±´ ê³„ì† ë³€í•˜ëŠ” ê°’ì´ë‹ˆê¹Œ ifë¬¸ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ.
    earliest_timestamp, latest_timestamp, opt = st.session_state['slider'][0], st.session_state['slider'][1], st.session_state['slider'][2]
    
    #start_date, end_dateëŠ” ìŠ¬ë¼ì´ë”ì—ì„œ ì„ íƒëœ ë‚ ì§œ ë²”ìœ„
    start_date, end_date = st.select_slider(
        '##### ë°ì´í„°ë¥¼ ì‚´í´ë³¼ ê¸°ê°„ì„ ì„ íƒí•˜ì„¸ìš”',
        options=opt,#optionsëŠ” ìŠ¬ë¼ì´ë”ì— ë“¤ì–´ê°ˆ ìˆ˜ ìˆëŠ” ëª¨ë“  ê°’ë“¤(ì¼ ê¸°ì¤€)
        value=(convert_to_date_in_string(earliest_timestamp), convert_to_date_in_string(latest_timestamp)), #valueëŠ” ìŠ¬ë¼ì´ë”ì˜ ì–‘ ë ê°’
        key = "date_slider" #sessionì— date_sliderë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ë“±ë¡
        )
    st.write(f'{start_date}' 'ë¶€í„°', f'{end_date}' 'ê¹Œì§€ì˜ ë°ì´í„°ë¥¼ ì‚´í´ë´…ë‹ˆë‹¤.')
    start_timestamp = pd.to_datetime(start_date, format="%Yë…„ %mì›” %dì¼")
    end_timestamp = pd.to_datetime(end_date, format="%Yë…„ %mì›” %dì¼")
    end_timestamp = end_timestamp.replace(hour = 23, minute = 59, second = 59) #ë ë‚ ì§œëŠ” ê·¸ ë‚ ì§œì˜ ë§ˆì§€ë§‰ ì‹œê°„ìœ¼ë¡œ í•´ì•¼ í•¨
#%%
with st.container():
    col1, col2, col3 = st.columns([1, 2, 1])#columnsëŠ” í™”ë©´ìƒ ì„¸ë¡œë¡œ ë‚˜ëˆ” [1, 2, 1]ì€ 1:2:1 ë¹„ìœ¨ë¡œ ë‚˜ëˆˆë‹¤ëŠ” ëœ»
    with col1:
        with st.container(border = True):
            #ê¸°ê°„ë³„ ì´ ì´ìš© ê±´ìˆ˜ ì¶œë ¥
            
            #ìŠ¬ë¼ì´ë”ë¡œ ì„ íƒí•œ ê¸°ê°„ë³„ í•„í„°ë§ëœ dfs ë§Œë“¤ê¸°
            def filter_dfs(dfs):
                filtered_dfs = dict()
                
                filtered_dfs['UserChat'] = dfs['UserChat'][(dfs['UserChat']['firstOpenedAt'] >= start_timestamp) & (dfs['UserChat']['firstOpenedAt'] <= end_timestamp)]
                filtered_dfs['Message'] = dfs['Message'][(dfs['Message']['createdAt'] >= start_timestamp) & (dfs['Message']['createdAt'] <= end_timestamp)]
                
                return filtered_dfs
            
            filtered_dfs = filter_dfs(dfs)
            
            #ê¸°ê°„ ë‚´ UserChatì„ ì›ë³¸ ë°ì´í„°ì—ì„œ ê±¸ëŸ¬ë‚´ê¸°
            #UserChatì˜ firstOpenedAtì´ Messageì˜ createdAtê³¼ ë™ì¼í•¨.
            #filtered_df_UserChat = dfs['UserChat'][(dfs['UserChat']['firstOpenedAt'] >= start_timestamp) & (dfs['UserChat']['firstOpenedAt'] <= end_timestamp)]
            
            
            #ì´ ì´ìš© ê±´ìˆ˜ ì¶œë ¥
            total_uses = filtered_dfs['UserChat'].shape[0]
            st.write("### ì´ ì´ìš© ê±´ìˆ˜")
            
            p_write(str(total_uses), 80, "bold", "center")
            #st.markdown('<p style="font-family:Malgun Gothic; text-align: center; font-size: 100px; font-weight: bold">'+f'{total_uses}'+'</p>', unsafe_allow_html=True)
        
        #%%
        with st.container(border = True):
            st.write("### ë¬¸ì˜ ìœ í˜• ë¶„ì„")
            #ìš°ì„  UserChatì˜ tagë“¤ì„ ë½‘ì•„ë‚´ê¸°
            #tagì—ëŠ” í•˜ë‚˜ ì´ìƒì˜ íƒœê·¸ë“¤ì´ ìˆìœ¼ë¯€ë¡œ, ', '(ë„ì–´ì“°ê¸° í¬í•¨! ì™œëƒí•˜ë©´ [ë°±ë¡œê·¸]ê±´ì˜,ì œì–¸ì²˜ëŸ¼ íƒœê·¸ ìì²´ì— ì‰¼í‘œ ìˆëŠ” ê²½ìš°ë„ ìˆê¸° ë•Œë¬¸)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë” ì„¸ë¶€ì ìœ¼ë¡œ ë½‘ì•„ë‚´ê¸°
            tags_ext_lst = []#íƒœê·¸ë§Œ ì¶”ì¶œí•œ ë¦¬ìŠ¤íŠ¸(í•œ elementì— í•œ ë°ì´í„°ì”©)
            
            for tags in filtered_dfs['UserChat']['tags'].tolist():
                if ', ' in tags:#', 'ë¡œ ë‚˜ëˆ ì„œ í•œ elementì— í•˜ë‚˜ì˜ íƒœê·¸ë§Œ ë“¤ì–´ê°€ê²Œ
                    tag_split = tags.split(', ')
                    for tag in tag_split:
                        tags_ext_lst.append(tag.strip())
                else:
                    tags_ext_lst.append(tags)
            
            #í•œ ë²ˆë„ ì•ˆ ì“°ì¸ íƒœê·¸ êµ¬í•˜ê¸°
            tag_set = dfs['UserChatTag']['name'] # UserChatTagsì— ìˆëŠ” ê²ƒë§Œ í™œìš©. ì¦‰, UserChatì—ì„œ'íƒœê·¸ ì—†ìŒ(NaN)'ì€ ë°ì´í„° ë¶„ì„ì—ì„œ ì œì™¸. 'íƒœê·¸ ì—†ìŒ' í¬í•¨í•˜ë ¤ë©´ tags_ext_lstì„ setìœ¼ë¡œ ê°ì‹¸ë©´ ë¨.
            tags_not_used = set([value for value in tag_set if value not in tags_ext_lst])
            
            #íƒœê·¸ ì¢…ë¥˜ë³„ë¡œ ê°œìˆ˜ë¥¼ ì„¸ê¸°
            tag_types = []
            tag_count = []
            for tag in tag_set:
                tag_types.append(tag)
                tag_count.append(tags_ext_lst.count(tag))
            
            df_tags_count = pd.DataFrame({'ë¬¸ì˜ ìœ í˜•':tag_types, 'ê±´ìˆ˜':tag_count}).sort_values(by='ê±´ìˆ˜', ascending=False)#ê±´ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            
            if not show_all:
                #ë¹„ìœ¨ì´ 0.05ê°€ ì•ˆ ë˜ëŠ” ê²ƒë“¤ì€ ê¸°íƒ€ë¡œ í•©ì¹˜ê¸°
                #ì›ë³¸ ë°ì´í„°ì˜ 'ê¸°íƒ€'ëŠ” ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€ë¡œ ë¹„ìœ¨ ê³„ì‚°
                ori_gita_count = int(df_tags_count.loc[df_tags_count['ë¬¸ì˜ ìœ í˜•'] == 'ê¸°íƒ€']['ê±´ìˆ˜'])#ì›ë³¸ ê¸°íƒ€ ê°œìˆ˜
                
                #ì›ë³¸ ë°ì´í„°ì˜ 'ê¸°íƒ€' í–‰ì€ ë¹¼ê¸°
                df_tags_count = df_tags_count[df_tags_count['ë¬¸ì˜ ìœ í˜•'] != 'ê¸°íƒ€']
                
                tags_sum_count = df_tags_count['ê±´ìˆ˜'].sum()
                tags_condition = (df_tags_count['ê±´ìˆ˜']/tags_sum_count) > 0.05
                df_tags_count_without_gita = df_tags_count[tags_condition] #ë¹„ìœ¨ìƒ 'ê¸°íƒ€ë¡œ ë¹ ì§€ëŠ” í–‰ë“¤(ì›ë³¸ ê¸°íƒ€ ê±´ìˆ˜ëŠ” ì´ë¯¸ ìœ„ì—ì„œ ë”°ë¡œ ì €ì¥í•´ ë†“ìŒ)'ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ í–‰ë“¤ ì €ì¥
                df_tags_count_gita = df_tags_count[~tags_condition]
                
                #ê¸°íƒ€ í–‰ ì¶”ê°€(ì›ë³¸ ê¸°íƒ€ ìˆ˜ + ë¹„ìœ¨ìƒ ê¸°íƒ€ ìˆ˜)
                sum_tags_gita = df_tags_count_gita['ê±´ìˆ˜'].sum() + ori_gita_count
                df_tags_count = df_tags_count_with_gita = pd.concat([df_tags_count_without_gita, pd.DataFrame([['ê¸°íƒ€', sum_tags_gita]], columns=df_tags_count_without_gita.columns)], ignore_index=True)
                
            
            
            #ë¬¸ì˜ ìœ í˜•ì˜ ìœ í˜•ìœ¼ë¡œ ë‹¤ì‹œ ë‚˜ëˆ„ê¸°
            #5ê°œë¡œ : [ë¸”ë™ë³´ë“œ], [ë„êµ¬], [ì˜¤ë¥˜], [ì¶œì„], ê¸°íƒ€
            #stacked bar chart
            st.write("##### ë¬¸ì˜ ìœ í˜•ì˜ ì¢…ë¥˜")
            tag_class = ['ë¸”ë™ë³´ë“œ', 'ë„êµ¬', 'ì˜¤ë¥˜', 'ì¶œì„']
            tag_class_count = []
            
            tmp_df= df_tags_count.copy()#ë³µì‚¬í•´ ë†“ê³  tag_classì— í•´ë‹¹í•˜ëŠ” ê±° ì¶”ì¶œí•´ì„œ ê°œìˆ˜ ì„¼ ë‹¤ìŒ í•´ë‹¹ í–‰ ì‚­ì œ
            for tc in tag_class:
                df_ = df_tags_count[df_tags_count['ë¬¸ì˜ ìœ í˜•'].str.contains('\['+tc+'\]')]#df_ë¡œ ê°œìˆ˜ ì…ˆ
                rm_idxes = df_.index#tmp_dfì—ì„œ ì‚­ì œí•  ì¸ë±ìŠ¤
                tmp_df = tmp_df.drop(rm_idxes, axis=0)#ì‚­ì œ
                tag_class_count.append(df_['ê±´ìˆ˜'].sum())#ê°œìˆ˜ëŠ” tag_class_count ë¦¬ìŠ¤íŠ¸ì— append
                
            #ë‚¨ì€ ê±´ ê¸°íƒ€ë¡œ append(show_allê³¼ ê´€ê³„ì—†ì´ ì›ë³¸ì´ ê¸°íƒ€ì¸ ê²ƒ!)
            tag_class.append('ê¸°íƒ€')
            tag_class_count.append(tmp_df['ê±´ìˆ˜'].sum())
            
            tmp_df = 0#ë©”ëª¨ë¦¬ ì ˆì•½ ìœ„í•´
            
            #ë¹„ìœ¨ ì—´ ì¶”ê°€
            tag_class_count_ratio = []
            for count in tag_class_count:
                tag_class_count_ratio.append(count/sum(tag_class_count))
            
            df_tag_class_count = pd.DataFrame({'ë¬¸ì˜ ìœ í˜•':tag_class, 'ê±´ìˆ˜':tag_class_count, 'v':['ë¬¸ì˜ ìœ í˜•']*5, 'ë¹„ìœ¨':tag_class_count_ratio})
            df_tag_class_count = df_tag_class_count.sort_values(by='ê±´ìˆ˜', ascending=False)
            df_tag_class_count = df_tag_class_count[df_tag_class_count['ê±´ìˆ˜'] != 0]#ê°œìˆ˜ 0ì¸ í–‰ ì œê±°
            #pd.DataFrame({'ê±´ìˆ˜':'ë¸”ë™ë³´ë“œ':tag_class_count[0], 'ë„êµ¬':tag_class_count[1], 'ì˜¤ë¥˜':tag_class_count[2], 'ì¶œì„':tag_class_count[3], 'ê¸°íƒ€':tag_class_count[4]}, columns=tag_class, index=[0])
            #print(df_tag_class_count)
            
            #altair stack bar chart
            c = alt.Chart(df_tag_class_count).mark_bar().encode(
                x=alt.X('sum(ê±´ìˆ˜):Q', title=None).stack("normalize"),
                y=alt.Y('v', title=None).axis(labels=False),
                color=alt.Color('ë¬¸ì˜ ìœ í˜•', scale=alt.Scale(domain=df_tag_class_count['ë¬¸ì˜ ìœ í˜•'].tolist())), # ì‹¬ë³¼ì„ ìˆ˜ë™ìœ¼ë¡œ ì¬ì •ì˜í•˜ê¸°: scale ê°ì²´ë¥¼ ì‚¬ìš©í•˜ì—¬ ë²”ë¡€ ì‹¬ë³¼ì„ ì§ì ‘ ì§€ì •. ì—¬ê¸°ì„  dataframeì˜ columnì„ ë”°ë¥´ë„ë¡ í•¨
                tooltip=['ë¬¸ì˜ ìœ í˜•', 'ê±´ìˆ˜', alt.Tooltip('ë¹„ìœ¨', format='.1%')],
                order=alt.Order(
                  # Sort the segments of the bars by this field
                  'sum(ê±´ìˆ˜):Q',
                  sort='descending'
                )
            )
            
            # í…ìŠ¤íŠ¸ ë ˆì´ë¸” ì •ì˜ ë° ì„œì‹ ì§€ì •
            text = alt.Chart(df_tag_class_count).mark_text(align='left', dy=-20, angle=330, color='black').encode(
                x=alt.X('sum(ê±´ìˆ˜):Q', title=None).stack("normalize"),
                y=alt.Y('v', title=None).axis(labels=False),
                text=alt.Text('ë¹„ìœ¨', format='.1%'),  # ë ˆì´ë¸”ë¡œ ì‚¬ìš©í•  dfì˜ ì—´
                #color=alt.Color('ë¬¸ì˜ ìœ í˜•'),
                tooltip=['ë¬¸ì˜ ìœ í˜•', 'ê±´ìˆ˜', alt.Tooltip('ë¹„ìœ¨', format='.1%')],
                order=alt.Order(
                  # Sort the segments of the bars by this field
                  'sum(ê±´ìˆ˜):Q',
                  sort='descending'
                )
            )#.properties(selection=alt.selection_single())
            c = c+text
            c = c.configure_legend(#ë²”ë¡€ ì„¤ì •
                orient='bottom', 
                direction='horizontal', 
                title=None
            )
            
            st.altair_chart(c, use_container_width=True)
            
            st.write("##### ìë™ íƒœê·¸ ë¶€ì°©")
            st.write("ì±„íŒ…ì„ ì…ë ¥í•´ ë³´ì„¸ìš”! AIê°€ ìë™ìœ¼ë¡œ ì¶”ì²œ íƒœê·¸ë¥¼ ë¶€ì°©í•©ë‹ˆë‹¤.")
            
            okt = Okt()
            
            if 'vectorizer' not in st.session_state:
                #vectorizer ë¶ˆëŸ¬ì˜¤ê¸°
                with open('vectorizer.pkl', 'rb') as pickle_file:
                    vectorizer = st.session_state['vectorizer'] = pickle.load(pickle_file)
            else:
                vectorizer = st.session_state['vectorizer']
                
            if 'classifier' not in st.session_state:
                #classifier ë¶ˆëŸ¬ì˜¤ê¸°
                with open('classifier.pkl', 'rb') as pickle_file:
                    classifier = st.session_state['classifier'] = pickle.load(pickle_file)
                
                
            else:
                classifier = st.session_state['classifier']
            
            def predict_tag(input_text, vectorizer, classifier):#okt ì„ ì–¸ ë’¤ì— ìˆì–´ì•¼ í•¨.
                tokenized_text = ' '.join(okt.nouns(input_text))
            
                # Vectorize the tokenized text
                input_vectorized = vectorizer.transform([tokenized_text])
            
                # Predict the tag
                predicted_tag = classifier.predict(input_vectorized)
                
                return predicted_tag[0]
            
            
            # Example usage:
            #input_text = input()
            #predicted_tag = predict_tag(input_text, vectorizer, classifier)
            
            #print(f"Predicted Tag: {predicted_tag}")
            
            
            text_input = st.text_input(
                label = "",
                label_visibility='collapsed',
                placeholder="ì—¬ê¸°ì— ì±„íŒ…ì„ ì…ë ¥í•˜ì„¸ìš”.",
            )
            
            if 'text_input' not in st.session_state:
                st.session_state['text_input'] = text_input
            
            #text_inputì´ ì—…ë°ì´íŠ¸ë  ë–„ë§Œ predict_tag ì‹¤í–‰
            if text_input != st.session_state['text_input']:
                st.session_state['text_input'] = text_input
                st.write(predict_tag(text_input, vectorizer, classifier))
            
            
            st.write("##### íƒœê·¸ë³„ ê±´ìˆ˜")
            
            #ë°ì´í„°í”„ë ˆì„ í‘œë¡œ ë³´ì´ê¸°
            st.dataframe(df_tags_count, use_container_width = True, hide_index = True,
                         column_config={
                        "ë¬¸ì˜ ìœ í˜•": st.column_config.Column(
                            width = 'medium'
                        ),
                        "ê±´ìˆ˜": st.column_config.Column(
                            width = 'small'
                        )
            })
            
     #%%       
    with col2:
        with st.container(border = True):
            st.write("### ì´ìš© í†µê³„ ê·¸ë˜í”„")
            st.write("##### ì‚¬ìš©ì ìœ í˜•ë³„ ì´ìš© ê±´ìˆ˜")
            #ì‚¬ìš©ì í†µê³„ ë³´ê¸° ì„ íƒ
            user_view_opt = st.selectbox(
                label = '',
                options = ('í•™ì  ìƒíƒœë¡œ ë³´ê¸°', 'ê³¼ì • ìƒíƒœë¡œ ë³´ê¸°', 'í•™ë…„ë³„ ë³´ê¸°(ê¸°íƒ€ ë° ë¯¸ì‹ë³„ ì œì™¸)'),
                label_visibility = "collapsed"#ë ˆì´ë¸” ì§€ìš°ê¸°(ê³µê°„ë„ ì—†ì•°); hiddenì€ ê³µê°„ì€ ë‚¨ê²¨ ë†“ìŒ
                )
            
            if user_view_opt == 'í•™ì  ìƒíƒœë¡œ ë³´ê¸°':
                select_col = 'profile.user_role'
            elif user_view_opt == 'ê³¼ì • ìƒíƒœë¡œ ë³´ê¸°':
                select_col = 'profile.course_role'
            elif user_view_opt == 'í•™ë…„ë³„ ë³´ê¸°(ê¸°íƒ€ ë° ë¯¸ì‹ë³„ ì œì™¸)':
                select_col = 'profile.education_level'
            
            #ê¸°ê°„ë³„ ì´ìš©ìë¥¼ user_roleë³„ë¡œ ë¶„ë¥˜í•˜ê¸°
            
            #ë¨¼ì € UserChatê³¼ User ë°ì´í„° í•©ì¹˜ê¸°(UserChat ì¤‘ì‹¬)
            #suffixesëŠ” ì—´ ì´ë¦„ ê°™ì€ ê²½ìš° ì ‘ë¯¸ì‚¬ ë¶™ì´ê¸° ê¸°ë³¸ê°’ì€ _x, _y
            df_Merged_UserChat_User= pd.merge(filtered_dfs['UserChat'], dfs['User'], left_on='userId', right_on='id', how='left', suffixes=('_Chat', '_User'))
            
            #í•©ì¹œ í›„ í•™ì /ê³¼ì •/í•™ë…„ ì—´ NaN ê°’ ì²˜ë¦¬
            if user_view_opt == 'í•™ë…„ë³„ ë³´ê¸°(ê¸°íƒ€ ë° ë¯¸ì‹ë³„ ì œì™¸)':
                df_Merged_UserChat_User[select_col] = df_Merged_UserChat_User[select_col][~df_Merged_UserChat_User[select_col].str.contains('ê¸°íƒ€|ë¯¸ì‹ë³„')]
                #UserChat ì¤‘ì‹¬ìœ¼ë¡œ í•©ì³¤ê¸° ë•Œë¬¸ì— nan ê°’ì´ ìˆì„ ìˆ˜ ìˆìŒ.
                df_Merged_UserChat_User = df_Merged_UserChat_User.dropna(subset=[select_col])
            else:
                #UserChat ì¤‘ì‹¬ìœ¼ë¡œ í•©ì³¤ê¸° ë•Œë¬¸ì— nan ê°’ì´ ìˆì„ ìˆ˜ ìˆìŒ.
                df_Merged_UserChat_User[select_col] = df_Merged_UserChat_User[select_col].fillna('ë¯¸ì‹ë³„(ë¡œê·¸ì¸ ì•ˆ í•¨)')
    
            #userì˜ idê°€ ì—†ëŠ” ê²½ìš° ë¡œê·¸ì¸í•˜ì§€ ì•Šê³  ì´ìš©í•œ ê²½ìš°ì¸ ë“¯.
            #imsi = df_Merged_User_UserChat[df_Merged_User_UserChat['id'].isna()]#'id'ê°€ NaNì¸ í•­ëª©ë§Œ ë½‘ì•„ë‚´ê¸°. personIdëŠ” ìˆê³ , userì˜ idëŠ” ì—†ëŠ” ê²½ìš°
            #print(imsi)
            
            #user_roleë³„ íŒŒì´ ì°¨íŠ¸ë¥¼ ìœ„í•œ ë°ì´í„° êµ¬ì¶•
            user_role_set = set(df_Merged_UserChat_User[select_col])
            user_role_lst = list(user_role_set)
            user_role_lst.sort()
            
            #ìƒ‰ìƒ íŒ”ë ˆíŠ¸
            #role ë²”ì£¼ë³„ ìƒ‰ìƒ ê³„ì—´ ìœ„í•´(ì¦‰, í•™ë¶€ ì¬í•™, í•™ë¶€ ì œì  ë“±ë“±ë¼ë¦¬ëŠ” ë¹„ìŠ·í•œ ìƒ‰ìœ¼ë¡œ í‘œì‹œí•˜ê¸° ìœ„í•´)
            #ê°•ì‚¬, êµì› : íŒŒë€ìƒ‰ ê³„ì—´
            #ëŒ€í•™ì› : ë¶‰ì€ìƒ‰ ê°œì—´
            #í•™ë¶€ : ì´ˆë¡ìƒ‰ ê³„ì—´
            #ê¸°íƒ€ : íšŒìƒ‰ ê³„ì—´
            
            def code_sum(string):
                cs = 0
                for c in string:
                    cs += ord(c)
                return cs
            
            def dec_to_rgb(i):
                r = (int((255+i)/3)* (i+7)) % 255
                g = (int((255-i)*5) * (i+31)) % 255
                b = (int((255+i)/11) * (i+59)) % 255
                
                return abs(r), abs(g), abs(b)
                
            
            def to_color_code(r, g, b):
                return '#'+ f'{r:02x}' + f'{g:02x}' + f'{b:02x}'
            
            def set_palette(user_role_lst):#user_roleì— ëŒ€í•œ ì •ë³´ ë°”ë€” ë•Œë§ˆë‹¤ íŒ”ë ˆíŠ¸ ë‹¤ì‹œ ì„¤ì •í•´ì•¼ í•¨(ì˜ˆ: ì¼ë¶€ ì •ë³´ 'ê¸°íƒ€'ë¡œ ìƒëµí•œ ê²½ìš°)
                palette = []
                for role in user_role_lst:
                    cs = code_sum(role)
                    r, g, b = dec_to_rgb(cs)
                    degree = 1.45
                    main_degree = 6.5
                    if re.search('ê°•ì‚¬|êµì›|êµìˆ˜ì', role):# or re.match('êµì›', role) or re.match('êµìˆ˜ì', role):
                        r = 44+int(r/degree)
                        g = 44+int(g/degree)
                        b = 255-int(b/main_degree)
                    elif re.search('ëŒ€í•™ì›|ìˆ˜ì—…ì¡°êµ', role):# or re.match('ìˆ˜ì—…ì¡°êµ', role):
                        r = 255-int(r/main_degree)
                        g = 44+int(g/degree)
                        b = 44+int(b/degree)
                    elif re.search('í•™ë¶€|í•™ìŠµì|\dí•™ë…„', role):# or re.match('í•™ìŠµì', role) or re.search('í•™ë…„', role):
                        r = 44+int(r/degree)
                        g = 255-int(g/main_degree)
                        b = 44+int(b/degree)
                    else:
                        r = 77+int(r/3)
                        g = 77+int(g/3)
                        b = 77+int(b/3)
                    palette.append(to_color_code(r, g, b))
                    
                return palette
            
            
            df_user_role_count = df_Merged_UserChat_User[select_col].value_counts().reset_index()
            df_user_role_count.columns=['ì‚¬ìš©ì ìœ í˜•', 'ê±´ìˆ˜']
            
            role_sum_count = df_user_role_count['ê±´ìˆ˜'].sum()
            
            if not show_all:
                #ë¹„ìœ¨ì´ 0.05ê°€ ì•ˆ ë˜ëŠ” ê²ƒë“¤ì€ ê¸°íƒ€ë¡œ í•©ì¹˜ê¸°
                condition = (df_user_role_count['ê±´ìˆ˜']/role_sum_count) > 0.05
                df_user_role_count_without_gita = df_user_role_count[condition] #ì¼ë‹¨ ê¸°íƒ€ë¡œ ë¹ ì§€ëŠ” í–‰ë“¤ì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ í–‰ë“¤ ì €ì¥
                df_user_role_count_gita = df_user_role_count[~condition]
                
                #ê¸°íƒ€ í–‰ ì¶”ê°€
                if df_user_role_count_gita['ê±´ìˆ˜'].sum() > 0:    
                    df_user_role_count_with_gita = pd.concat([df_user_role_count_without_gita, pd.DataFrame([['ê¸°íƒ€', df_user_role_count_gita['ê±´ìˆ˜'].sum()]], columns=df_user_role_count_without_gita.columns)], ignore_index=True)
                else:
                    df_user_role_count_with_gita = df_user_role_count_without_gita
                
                df_user_role_count = df_user_role_count_with_gita
                
                
            if use_phnetax_theme:
                #íŒ”ë ˆíŠ¸ ì—…ë°ì´íŠ¸
                palette = set_palette(sorted(list(set(df_user_role_count['ì‚¬ìš©ì ìœ í˜•']))))
                
            
            #ë¹„ìœ¨ ì—´ ì¶”ê°€
            user_role_count_ratio = []
            for count in df_user_role_count['ê±´ìˆ˜']:
                user_role_count_ratio.append(count/df_user_role_count['ê±´ìˆ˜'].sum())
            
            df_user_role_count['ë¹„ìœ¨'] = user_role_count_ratio
            
            base = alt.Chart(df_user_role_count).encode(
                alt.Theta("ê±´ìˆ˜:Q").stack(True),#Theta ì¶•ì„ "ê±´ìˆ˜" ì—´ë¡œ ì§€ì •í•˜ê³ , stack íŒŒë¼ë¯¸í„°ë¥¼ Trueë¡œ ì„¤ì •í•˜ì—¬ ë°ì´í„°ë¥¼ ì¤‘ì²©ì‹œí‚µë‹ˆë‹¤.
                alt.Radius("ê±´ìˆ˜").scale(type="sqrt", zero=True, rangeMin=20),#ë°˜ì§€ë¦„(Radius)ì„ "values" ì—´ë¡œ ì§€ì •í•˜ê³ , ìŠ¤ì¼€ì¼ë§ì„ ì„¤ì •í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” ì œê³±ê·¼ ìŠ¤ì¼€ì¼ë§ì„ ì‚¬ìš©í•˜ê³ , ìµœì†Œê°’ì„ 20ìœ¼ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.
                color=alt.Color('ì‚¬ìš©ì ìœ í˜•:N', scale=alt.Scale(range=palette)) if use_phnetax_theme else 'ì‚¬ìš©ì ìœ í˜•:N',#, domain=df_user_role_count['ì‚¬ìš©ì ìœ í˜•'].tolist())),
                tooltip=['ê±´ìˆ˜', 'ì‚¬ìš©ì ìœ í˜•', alt.Tooltip('ë¹„ìœ¨', format='.1%')],
                order=alt.Order(
                  # Sort the segments of the bars by this field
                  'ê±´ìˆ˜:Q',
                  sort='descending'
                )
            )
            
            chart1 = base.mark_arc(innerRadius=20, stroke="#fff")
            
            chart2 = base.mark_text(radiusOffset=50).encode(text="ì‚¬ìš©ì ìœ í˜•:N",
                                                            color=alt.value('black'))
            chart4 = base.mark_text(radiusOffset=15).encode(text=alt.Text('ë¹„ìœ¨', format='.1%'),
                                                            color=alt.value('black'))
            chart3 = chart1 + chart2 + chart4
            
            
            #c1, c2, c3 = st.columns([1, 6, 1])
            #with c2:
            st.altair_chart(chart3, use_container_width=True)
            
            def to_pydt(timestamp):
                return timestamp.to_pydatetime()
            def to_date(pydatetime):
                return pydatetime.date()
            
            #ì•„ë˜ ë‘ ê·¸ë˜í”„ì—ì„œ ì‚¬ìš©í•  ì‚¬ìš©ì ìœ í˜• ë²”ì£¼
            tab1, tab2 = st.tabs(["ê¸°ê°„ë³„ ì´ìš© ì¶”ì´", "ì±—ë´‡ ë¬¸ì˜ í‚¤ì›Œë“œ ìˆœìœ„"])
            if user_view_opt == 'í•™ì  ìƒíƒœë¡œ ë³´ê¸°':#ì´ë•Œë§Œ 'ê³„ì—´'ë¡œ êµ¬ë¶„(í•™ë¶€ ì¬í•™, í•™ë¶€ íœ´í•™, í•™ë¶€ ì œì ... ë„ˆë¬´ ë§ê¸° ë•Œë¬¸)
                sel_role = ['êµì›/ê°•ì‚¬', 'ëŒ€í•™ì›', 'í•™ë¶€', 'í•™ì êµë¥˜/êµí™˜í•™ìƒ', 'ê¸°íƒ€']
            else:
                sel_role = user_role_lst
                
            sel_role.insert(0, "ì „ì²´")
            with tab1:
                #ìœ ì € ìœ í˜• ì„ íƒ
                st.write("ì‚¬ìš©ì ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”.")
                #radio button ì¶œë ¥
                select_role = st.radio(
                    label = '',
                    options = sel_role,
                    label_visibility="collapsed",
                    horizontal=True,
                    key="select_role"
                )
                
                #ê¸°ê°„ë³„ ì´ìš© ì¶”ì´ ì¶œë ¥
                
                #ê¸°ê°„ë³„ ì´ìš© ì¶”ì´ ë°ì´í„° í•„í„°ë§
                df_period_usage = df_Merged_UserChat_User[['firstOpenedAt', select_col]]
                
                #ì„ íƒì— ë”°ë¼ ë°ì´í„° í•„í„°ë§
                if select_role != "ì „ì²´":
                    if user_view_opt == 'í•™ì  ìƒíƒœë¡œ ë³´ê¸°':#ì´ë•Œë§Œ 'ê³„ì—´'ë¡œ êµ¬ë¶„(í•™ë¶€ ì¬í•™, í•™ë¶€ íœ´í•™, í•™ë¶€ ì œì ... ë„ˆë¬´ ë§ê¸° ë•Œë¬¸)
                        if select_role == 'êµì›/ê°•ì‚¬':
                            df_period_usage = df_period_usage[df_period_usage[select_col].str.contains('êµì›|ê°•ì‚¬')]
                        elif select_role == 'í•™ì êµë¥˜/êµí™˜í•™ìƒ':
                            df_period_usage = df_period_usage[df_period_usage[select_col].str.contains('í•™ì êµë¥˜|êµí™˜í•™ìƒ')]
                        elif select_role == 'ëŒ€í•™ì›' or select_role == 'í•™ë¶€':
                            df_period_usage = df_period_usage[df_period_usage[select_col].str.contains(select_role)]
                        else:#ê¸°íƒ€ì¸ ê²½ìš°
                            all_but_gita = []
                            for r in sel_role:
                                if '/' in r:
                                    r.split('/')
                                    all_but_gita.extend(r)
                                else:
                                    all_but_gita.append(r)
                            cond_str = '|'.join(all_but_gita)#êµì›|ê°•ì‚¬|í•™ì êµë¥˜|... ì´ëŸ° ì‹ìœ¼ë¡œ ë§Œë“¤ê¸°
                            condition = df_period_usage[select_col].str.contains(cond_str)
                            df_period_usage = df_period_usage[~condition]
                    else:
                        if select_role != "ì „ì²´":
                            df_period_usage = df_period_usage[df_period_usage[select_col]==select_role]
                            
                st.write("##### ê¸°ê°„ë³„ ì´ìš© ì¶”ì´")
                if not show_all:
                    #5% ì•ˆ ë˜ëŠ” ê±° ê¸°íƒ€ë¡œ ëº´ê¸°(ìœ„ì—ì„œ ë§Œë“  ê±° í™œìš©)
                    user_role_gita = set(df_user_role_count_gita['ì‚¬ìš©ì ìœ í˜•'])#ê¸°íƒ€ì— í•´ë‹¹í•˜ëŠ” user_role ì¶”ì¶œ
                    df_period_usage.loc[df_period_usage[select_col].isin(user_role_gita), select_col] = 'ê¸°íƒ€'#ê¸°íƒ€ì— í•´ë‹¹í•˜ëŠ” user_role ê°’ë“¤ì„ ëª¨ë‘ 'ê¸°íƒ€'ë¡œ ë°”ê¾¸ê¸°
                
                if use_phnetax_theme:
                    palette = set_palette(sorted(list(set(df_period_usage[select_col])))) #íŒ”ë ˆíŠ¸ ì—…ë°ì´íŠ¸
                #pd.timestampë¥¼ pydatetimeìœ¼ë¡œ ë°”ê¾¸ê¸°
                df_period_usage['firstOpenedAt'] = df_period_usage['firstOpenedAt'].apply(to_pydt).apply(to_date)
                #st.write(df_period_usage)
                
                #ë‚ ì§œë³„ë¡œ ê°œìˆ˜ ì„¸ê¸°
                #ìš°ì„  roleì˜ ê°œìˆ˜ë§Œí¼ ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ê¸°(0ìœ¼ë¡œ ì´ˆê¸°í™”)
                #date_user_role_count = dict()
                #for r in user_role_set:
                #    date_user_role_count[r] = []
                #
                #date_lst = []
                
                #ë‚ ì§œë³„, user_roleë³„ ê°œìˆ˜ ì„¸ê¸°
                
                #for date in set(df_period_usage['firstOpenedAt']):
                #    date_lst.append(date)
                #    for role in user_role_set:
                #        cond = (df_period_usage['firstOpenedAt'] == date) & (df_period_usage[select_col] == role)
                #        date_user_role_count[role].append(len(df_period_usage[cond]))
                        
                #ê°œìˆ˜ ì„¼ ê±¸ë¡œ ë°ì´í„°í”„ë ˆì„ ë§Œë“¤ê¸°
                #df_date = pd.DataFrame({'ë‚ ì§œ':date_lst})
                #df_user_role_count = pd.DataFrame(date_user_role_count)
                #df_byPeriod_byRole_usage = pd.concat([df_date, df_user_role_count], axis=1)
                
                #df_byPeriod_byRole_usage = df_period_usage.groupby('firstOpenedAt', select_col).size().unstack().fillna(0)
                #groupby() ë©”ì„œë“œëŠ” ë°ì´í„°í”„ë ˆì„ì„ íŠ¹ì • ì—´(ë˜ëŠ” ì—´ë“¤)ì„ ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.
                #size() ë©”ì„œë“œëŠ” ê·¸ë£¹í™”ëœ ë°ì´í„°í”„ë ˆì„ì—ì„œ ê° ê·¸ë£¹ì˜ í¬ê¸°(í–‰ì˜ ê°œìˆ˜)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
                #unstack() ë©”ì„œë“œëŠ” ê·¸ë£¹í™”ëœ ë°ì´í„°í”„ë ˆì„ì—ì„œ íŠ¹ì • ì—´ì„ í–‰ ì¸ë±ìŠ¤ë¡œ ë³€í™˜í•˜ì—¬ ìƒˆë¡œìš´ ì—´ì„ ìƒì„±í•©ë‹ˆë‹¤.
                
                #altair ì°¨íŠ¸ ê·¸ë¦´ ë• ì´ê±¸ë¡œ
                df_byPeriod_byRole_usage = df_period_usage.groupby(['firstOpenedAt', select_col]).size().reset_index(name='Count')
                df_byPeriod_byRole_usage = df_byPeriod_byRole_usage.rename(columns={'firstOpenedAt':'ë‚ ì§œ', select_col:'ì‚¬ìš©ì ìœ í˜•', 'Count':'ê±´ìˆ˜'})
                
                #st.write(user_role_lst)
                #st.write(palette)
                period_usage_chart = alt.Chart(df_byPeriod_byRole_usage).mark_bar().encode(
                    x=alt.X('ë‚ ì§œ', title=None),
                    y=alt.X('ê±´ìˆ˜:Q', title=None),
                    color=alt.Color('ì‚¬ìš©ì ìœ í˜•:N', scale=alt.Scale(range=palette)) if use_phnetax_theme else 'ì‚¬ìš©ì ìœ í˜•:N'#'ì‚¬ìš©ì ìœ í˜•:N'
                )
                    
                st.altair_chart(period_usage_chart, use_container_width=True)
            
            with tab2:
                #ìœ ì € ìœ í˜• ì„ íƒ
                st.write("ì‚¬ìš©ì ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”.")
                
                #radio button ì¶œë ¥
                select_role2 = st.radio(
                    label = '',
                    options = sel_role,
                    label_visibility="collapsed",
                    horizontal=True,
                    key="select_role2"
                )
                
                #ì±—ë³¸ ë¬¸ì˜ í‚¤ì›Œë“œ ìˆœìœ„ ë°ì´í„° í•„í„°ë§
                st.write("##### ì±—ë´‡ ë¬¸ì˜ í‚¤ì›Œë“œ ìˆœìœ„")
                
                #ë°ì´í„° ì²˜ë¦¬ëŠ” í•´ì•¼ í•¨. ì‹¤ì œ í‚¤ì›Œë“œ ì¶”ì¶œë§Œ(keyword_extract) ì´ê±°ì— ë”°ë¼ ì—…ë°ì´íŠ¸í•˜ëŠ”ì§€ ê²°ì •
                if 'keyword_rating_update_side' in st.session_state:
                    keyword_rating_update = st.toggle('ì—…ë°ì´íŠ¸', value=st.session_state['keyword_rating_update_side'], key='keyword_rating_update')
                else:
                    keyword_rating_update = st.toggle('ì—…ë°ì´íŠ¸', value=True, key='keyword_rating_update')
                
                st.write("'ì—…ë°ì´íŠ¸'ë¥¼ ë„ë©´ í™”ë©´ ì¡°ì‘ ì‹œ ì²˜ë¦¬ ì‹œê°„ì´ ì¤„ì–´ë“­ë‹ˆë‹¤.")
                
                df_Merged_User_Message= pd.merge(dfs['User'], filtered_dfs['Message'], left_on='id', right_on='personId', how='right', suffixes=('_User', '_Chat'))
                
                #ì„ íƒì— ë”°ë¼ ë°ì´í„° í•„í„°ë§
                if select_role2 != "ì „ì²´":
                    if user_view_opt == 'í•™ì  ìƒíƒœë¡œ ë³´ê¸°':#ì´ë•Œë§Œ 'ê³„ì—´'ë¡œ êµ¬ë¶„(í•™ë¶€ ì¬í•™, í•™ë¶€ íœ´í•™, í•™ë¶€ ì œì ... ë„ˆë¬´ ë§ê¸° ë•Œë¬¸)
                        if select_role2 == 'êµì›/ê°•ì‚¬':
                            df_Merged_User_Message = df_Merged_User_Message[df_Merged_User_Message[select_col].str.contains('êµì›|ê°•ì‚¬')]
                        elif select_role2 == 'í•™ì êµë¥˜/êµí™˜í•™ìƒ':
                            df_Merged_User_Message = df_Merged_User_Message[df_Merged_User_Message[select_col].str.contains('í•™ì êµë¥˜|êµí™˜í•™ìƒ')]
                        elif select_role2 == 'ëŒ€í•™ì›' or select_role2 == 'í•™ë¶€':
                            df_Merged_User_Message = df_Merged_User_Message[df_Merged_User_Message[select_col].str.contains(select_role2)]
                        else:#ê¸°íƒ€ì¸ ê²½ìš°
                            all_but_gita = []
                            for r in sel_role:
                                if '/' in r:
                                    r.split('/')
                                    all_but_gita.extend(r)
                                else:
                                    all_but_gita.append(r)
                            cond_str = '|'.join(all_but_gita)#êµì›|ê°•ì‚¬|í•™ì êµë¥˜|... ì´ëŸ° ì‹ìœ¼ë¡œ ë§Œë“¤ê¸°
                            condition = df_Merged_User_Message[select_col].str.contains(cond_str)
                            df_Merged_User_Message = df_Merged_User_Message[~condition]
                    else:
                        if select_role2 != "ì „ì²´":
                            df_Merged_User_Message = df_Merged_User_Message[df_Merged_User_Message[select_col]==select_role2]
                
                
                message = ''
                for t in df_Merged_User_Message['plainText']:
                  message = message + str(t)
                
                @st.cache_data
                def keyword_extract(message):
                    message_N = okt.nouns(message)#ëª…ì‚¬ë§Œ ì¶”ì¶œ
                    counter = Counter(message_N)#ëª…ì‚¬ì˜ ê°œìˆ˜ë¥¼ ì„¸ê¸°
                    return counter
                
                
                if keyword_rating_update:#keyword ì—…ë°ì´íŠ¸
                    keyword_counter = st.session_state['keyword_count'] = keyword_extract(message)
                else:
                    if 'keyword_count' not in st.session_state:
                        keyword_counter = st.session_state['keyword_count'] = keyword_extract(message)
                    else:
                        keyword_counter = st.session_state['keyword_count']
                
                stopwords = [key for key, count in keyword_counter.items() if len(key) == 1]
                for s in stopwords:
                    del keyword_counter[s]
                
                count_col1, count_col2 = st.columns([1, 1])
                with count_col1:
                    #ìƒìœ„ %ë§Œ
                    percent = st.slider('', 1, 100, 1, label_visibility='collapsed', disabled = not keyword_rating_update)
                    st.write("ìƒìœ„", percent, '%ë§Œ í‘œì‹œí•©ë‹ˆë‹¤.')
                with count_col2:
                    #ë¹ˆë„ nê°œ ì´ìƒë§Œ
                    count_min = min(keyword_counter.values())
                    count_max = max(keyword_counter.values())
                    if count_min != count_max:
                        count_cut = st.slider('', count_min, count_max, count_min, label_visibility='collapsed', disabled = not keyword_rating_update)
                        st.write(count_cut, 'ê°œ ì´ìƒë§Œ í‘œì‹œí•©ë‹ˆë‹¤.')
                
                #ìƒìœ„ë¡œ ë½‘ì€ ê²ƒë“¤ ì¤‘ì—ì„œ ê°œìˆ˜ê°€ 10ê°œê°€ ì±„ ì•ˆ ë˜ëŠ” ê²ƒë“¤ì€ ì—†ì• ê¸° 
                keys_to_remove = [k for k, c in keyword_counter.items() if c < count_cut]
                for k in keys_to_remove:
                    del keyword_counter[k]
                
                nTop_percent = int(sum(keyword_counter.values()) * (percent*0.01))
                if nTop_percent < 1:
                    nTop_percent = int(sum(keyword_counter.values()))
                keyword_top = keyword_counter.most_common(nTop_percent)
                
                df_word_count = pd.DataFrame({'í‚¤ì›Œë“œ':[k for k, c in keyword_top], 'ë¹ˆë„ ìˆ˜':[c for k, c in keyword_top]})
                df_word_count = df_word_count.sort_values(by='ë¹ˆë„ ìˆ˜', ascending=False)#reset_index()
                    
                #ë¹ˆë„ ìˆ˜ì— ë”°ë¥¸ íˆìŠ¤í† ê·¸ë¨ ê·¸ë¦¬ê¸°
                bar = alt.Chart(df_word_count).mark_bar().encode(
                    x=alt.X('í‚¤ì›Œë“œ:N', title=None, sort=alt.EncodingSortField(field='ë¹ˆë„ ìˆ˜', op='sum', order='descending')),
                    y=alt.Y('ë¹ˆë„ ìˆ˜:Q', title=None)
                )
                
                rule = alt.Chart(df_word_count).mark_rule(color='red').encode(
                    y='mean(ë¹ˆë„ ìˆ˜):Q'
                )
                    
                st.altair_chart(bar + rule, use_container_width=True)
            
        #%%
    with col3:
        with st.container(border = True):
            st.write("### ì‹œê°„ í†µê³„")
            st.write("##### ì¼ì¸ë‹¹ ìƒë‹´ ì‹œê°„ í‰ê· ")
            #ìƒë‹´ ì‹œê°„ í‰ê·  ì¶œë ¥
            mean_time = filtered_dfs['UserChat']['operationTotalReplyTime'].mean()
            if mean_time.components.hours > 1:
                p_write(f"{mean_time.components.hours}ì‹œê°„ {mean_time.components.minutes}ë¶„ {mean_time.components.seconds}ì´ˆ", 40, "bold", "center")
            else:
                p_write(f"{mean_time.components.minutes}ë¶„ {mean_time.components.seconds}ì´ˆ", 70, "bold", "center")
            
            #ì ˆì•½ ì‹œê°„ ì¶œë ¥
            total_time = filtered_dfs['UserChat']['operationTotalReplyTime'].sum()
            
            additional_str_font_size = 20
            total_str1 = span_write("ì´ ", font_size=additional_str_font_size, writeHTML=False)
            total_str2 = span_write(f"{total_time.components.days * 24 + total_time.components.hours}ì‹œê°„ {total_time.components.minutes}ë¶„ {total_time.components.seconds}ì´ˆ", font_size=additional_str_font_size, color=PRIMARY_COLOR, font_weight="bold", writeHTML=False)
            total_str3 = span_write(" ìƒë‹´", font_size=additional_str_font_size, writeHTML=False)
            st.markdown(f'<p style="text-align:center">{total_str1}{total_str2}{total_str3}</p>', unsafe_allow_html=True)
            
            st.write("##### ì¼ì¸ë‹¹ ì‘ë‹µ ëŒ€ê¸° ì‹œê°„ í‰ê· ")
            waiting_mean = filtered_dfs['UserChat']['operationWaitingTime'].mean()
            p_write(f"{waiting_mean.components.minutes}ë¶„ {waiting_mean.components.seconds}ì´ˆ", 70, "bold", "center")
            
            waiting_min = filtered_dfs['UserChat']['operationWaitingTime'].min()
            waiting_max = filtered_dfs['UserChat']['operationWaitingTime'].max()
            min_str = span_write(f"ìµœì†Œ {waiting_min.components.hours}ì‹œê°„ {waiting_min.components.minutes}ë¶„ {waiting_min.components.seconds}ì´ˆ", font_size=additional_str_font_size, color="green", font_weight="bold", writeHTML=False)
            max_str = span_write(f"ìµœëŒ€ {waiting_max.components.hours}ì‹œê°„ {waiting_max.components.minutes}ë¶„ {waiting_max.components.seconds}ì´ˆ", font_size=additional_str_font_size, color="red", font_weight="bold", writeHTML=False)
            st.markdown(f'<p style="text-align:center">{min_str}<br>{max_str}</p>', unsafe_allow_html=True)
            
        with st.container(border = True):
            st.write("### ì±—ë´‡ ë¬¸ì˜ í‚¤ì›Œë“œ ì‹œê°í™”")
            if 'word_cloud_update_side' in st.session_state:
                word_cloud_update = st.toggle('ì—…ë°ì´íŠ¸', value=st.session_state['word_cloud_update_side'], key='word_cloud_update')
            else:
                word_cloud_update = st.toggle('ì—…ë°ì´íŠ¸', value=True, key='word_cloud_update')
            st.write("'ì—…ë°ì´íŠ¸'ë¥¼ ë„ë©´ í™”ë©´ ì¡°ì‘ ì‹œ ì²˜ë¦¬ ì‹œê°„ì´ ì¤„ì–´ë“­ë‹ˆë‹¤.")
            if word_cloud_update:
                wc = WordCloud("NanumBarunGothic.ttf", background_color='white')
                cloud=wc.generate_from_frequencies(keyword_counter)
                
                fig = st.session_state['word_cloud_fig'] = plt.figure()#figsize=(8,8)
                plt.imshow(cloud)
                plt.axis('off')
            #plt.show()
            if 'word_cloud_fig' in st.session_state:
                st.pyplot(st.session_state['word_cloud_fig'])
